{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0c9266",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1b4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61722b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(x):\n",
    "# empty list to hold the header tags \n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "# requesting the page\n",
    "\n",
    "    wikipedia = requests.get(x)\n",
    "    soup=BeautifulSoup(wikipedia.content)\n",
    "\n",
    "# list for the header tags\n",
    "    L=['h1', 'h2','h3']\n",
    "    for j in L:\n",
    "    \n",
    "        for i in soup.find_all(j):\n",
    "            \n",
    "# To scrap the data according to the header tag\n",
    "\n",
    "            if(j == 'h1'):\n",
    "                h1.append(i.text)\n",
    "            if(j == 'h2'):\n",
    "                h2.append(i.text)\n",
    "            if(j == 'h3'):\n",
    "                h3.append(i.text)\n",
    "    \n",
    "    return (\"Heading h1\",h1,\" Heading h2\",h2,\" Heading h3\",h3)\n",
    "# return the asked values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b870ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://en.wikipedia.org/wiki/Main_Page\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Heading h1',\n",
       " ['Main Page', 'Welcome to Wikipedia'],\n",
       " ' Heading h2',\n",
       " [\"From today's featured article\",\n",
       "  'Did you know\\xa0...',\n",
       "  'In the news',\n",
       "  'On this day',\n",
       "  \"From today's featured list\",\n",
       "  \"Today's featured picture\",\n",
       "  'Other areas of Wikipedia',\n",
       "  \"Wikipedia's sister projects\",\n",
       "  'Wikipedia languages',\n",
       "  'Navigation menu'],\n",
       " ' Heading h3',\n",
       " ['\\nSearch\\n'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url: https://en.wikipedia.org/wiki/Main_Page\n",
    "scraping(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc19f13",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a036628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMDB(x):\n",
    "#      request the url\n",
    "    im= requests.get(x)\n",
    "    \n",
    "#     scrap all content\n",
    "    Content=BeautifulSoup(im.content)\n",
    "    \n",
    "#     empty list to store values\n",
    "    Movie=[]\n",
    "    Year=[]\n",
    "    Rating=[]\n",
    "    Rank=[]\n",
    "    \n",
    "#     scraping data \n",
    "    for i in Content.find_all('td',class_=\"titleColumn\"):\n",
    "        Movie.append(i.text.replace(\"\\n\", \"\")[14:-6])\n",
    "\n",
    "    \n",
    "    for i in Content.find_all('span',class_=\"secondaryInfo\"):\n",
    "        Year.append(i.text)\n",
    "    \n",
    "    \n",
    "    for i in Content.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        Rating.append(i.text.replace(\"\\n\", \"\"))\n",
    "        \n",
    "    \n",
    "    for i in range(1,len(Movie)+1):\n",
    "        Rank.append(i)\n",
    "        \n",
    "#     importing library\n",
    "    import pandas as pd\n",
    "    \n",
    "#     creating dataframe\n",
    "    data=pd.DataFrame({\"Ranking\":Rank,\"Movie\":Movie,'Year':Year,'Ratings':Rating,})\n",
    "    \n",
    "    data.set_index('Ranking',inplace =True)\n",
    "    \n",
    "    data=data[0:100]\n",
    "    \n",
    "#     store the data\n",
    "    data.to_csv('imdb.csv')                         \n",
    "    \n",
    "#   display the data scraped\n",
    "    return data                                     \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e8f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.imdb.com/chart/top/?ref_=nv_mv_250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>(1962)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Movie    Year Ratings\n",
       "Ranking                                                    \n",
       "1                  The Shawshank Redemption  (1994)     9.2\n",
       "2                             The Godfather  (1972)     9.2\n",
       "3                           The Dark Knight  (2008)     9.0\n",
       "4                    The Godfather: Part II  (1974)     9.0\n",
       "5                              12 Angry Men  (1957)     8.9\n",
       "...                                     ...     ...     ...\n",
       "96                       Lawrence of Arabia  (1962)     8.3\n",
       "97                                   Jagten  (2012)     8.3\n",
       "98        M - Eine Stadt sucht einen Mörder  (1931)     8.3\n",
       "99                       North by Northwest  (1959)     8.3\n",
       "100                                 Vertigo  (1958)     8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## url: https://www.imdb.com/chart/top/?ref_=nv_mv_250\n",
    "IMDB(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad3ce2",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c41cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bollywood(z):\n",
    "    # requesting the url\n",
    "    Indian_IMBD= requests.get(z)\n",
    "    \n",
    "#     scraping the page content\n",
    "    Content=BeautifulSoup(Indian_IMBD.content)\n",
    "    \n",
    "#     empty list to store data\n",
    "    film=[]\n",
    "    Movies=[]\n",
    "    Year=[]\n",
    "    Rating=[]\n",
    "    Rank=[]\n",
    "    \n",
    "#     scrapping the neede portion\n",
    "\n",
    "    for i in Content.find_all('div',class_=\"lister-item-content\"):\n",
    "        film.append(i.text[5::])\n",
    "    for j in range(100):\n",
    "        film[j]=film[j].split(\"\\n\")\n",
    "\n",
    "    l=[29,41,44,53,56,58,66,70,73,77,83,86,92,95,96]\n",
    "    for k in range(0,100):\n",
    "        if(k<=8):\n",
    "            Movies.append(film[k][0])\n",
    "            Year.append(film[k][1])\n",
    "            Rating.append(film[k][20])\n",
    "        elif(k in l):\n",
    "            Movies.append(film[k][1])\n",
    "            Year.append(film[k][2])\n",
    "            Rating.append(film[k][19])\n",
    "        else:\n",
    "            Movies.append(film[k][1])\n",
    "            Year.append(film[k][2])\n",
    "            Rating.append(film[k][21])\n",
    "        \n",
    "    \n",
    "    for i in range(1,len(Movies)+1):\n",
    "        Rank.append(i)\n",
    "\n",
    "#         importing libraray\n",
    "    import pandas as pd\n",
    "    \n",
    "#     creating dataframe\n",
    "    Bollywood=pd.DataFrame({\"Ranking\":Rank,\"Movie\":Movies,'Year':Year,'Ratings':Rating,})\n",
    "    \n",
    "    Bollywood.set_index('Ranking',inplace =True)\n",
    "    \n",
    "#     storing data in csv\n",
    "    Bollywood.to_csv('imdb.csv')\n",
    "    \n",
    "# display the data\n",
    "    return Bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e851db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.imdb.com/list/ls056092300/?sort=user_rating,desc&st_dt=&mode=detail&page=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sagara Sangamam</td>\n",
       "      <td>(1983)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goopy Gyne Bagha Byne</td>\n",
       "      <td>(1969)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pushpaka Vimana</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vanaja</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Amma Ariyan</td>\n",
       "      <td>(1986)</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Enthiran</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chandni</td>\n",
       "      <td>(1989)</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Neecha Nagar</td>\n",
       "      <td>(1946)</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Movie    Year Ratings\n",
       "Ranking                                       \n",
       "1              Sagara Sangamam  (1983)     8.8\n",
       "2        Goopy Gyne Bagha Byne  (1969)     8.7\n",
       "3                      Nayakan  (1987)     8.6\n",
       "4              Pushpaka Vimana  (1987)     8.6\n",
       "5                  Apur Sansar  (1959)     8.5\n",
       "...                        ...     ...     ...\n",
       "96                      Vanaja  (2006)     7.1\n",
       "97                 Amma Ariyan  (1986)     7.1\n",
       "98                    Enthiran  (2010)       7\n",
       "99                     Chandni  (1989)     6.7\n",
       "100               Neecha Nagar  (1946)     6.7\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## url:https://www.imdb.com/list/ls056092300/?sort=user_rating,desc&st_dt=&mode=detail&page=1\n",
    "Bollywood(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cd8fd",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "# from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "541efa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def President(xyz):\n",
    "#     requesting the page\n",
    "    former_president= requests.get(xyz)\n",
    "    \n",
    "# content of page scrapped\n",
    "    Content=BeautifulSoup(former_president.content)\n",
    "    Information=[]\n",
    "    president=[]\n",
    "    Term=[]\n",
    "    rank=[]\n",
    "    \n",
    "# fetching the asked information\n",
    "    for i in Content.find_all('div',class_=\"presidentListing\"):\n",
    "        Information.append(i.text.split(\"\\n\"))\n",
    "\n",
    "    for i in range(len(Information)):\n",
    "        president.append(Information[i][1])\n",
    "        Term.append(Information[i][2])\n",
    "    \n",
    "    for i in range(len(president)):\n",
    "        president[i]=president[i].split(\"(\")\n",
    "        president[i]=president[i][0]\n",
    "    \n",
    "    for i in range(len(Term)):\n",
    "        Term[i]=Term[i].split(\":\")\n",
    "        Term[i]=Term[i][1]\n",
    "    \n",
    "    \n",
    "    for i in range(1,len(president)+1):\n",
    "        rank.append(i)\n",
    "\n",
    "    import pandas as pd\n",
    "    \n",
    "#     craeting the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":rank,\"Former President\":president,\"Term of Office\": Term})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     storing the data\n",
    "    DATA.to_csv('President.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39515b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://presidentofindia.nic.in/former-presidents.htm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former President</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Former President  \\\n",
       "S.No                                  \n",
       "1            Shri Pranab Mukherjee    \n",
       "2     Smt Pratibha Devisingh Patil    \n",
       "3           DR. A.P.J. Abdul Kalam    \n",
       "4             Shri K. R. Narayanan    \n",
       "5          Dr Shankar Dayal Sharma    \n",
       "6              Shri R Venkataraman    \n",
       "7                 Giani Zail Singh    \n",
       "8        Shri Neelam Sanjiva Reddy    \n",
       "9         Dr. Fakhruddin Ali Ahmed    \n",
       "10    Shri Varahagiri Venkata Giri    \n",
       "11                Dr. Zakir Husain    \n",
       "12    Dr. Sarvepalli Radhakrishnan    \n",
       "13             Dr. Rajendra Prasad    \n",
       "\n",
       "                                         Term of Office  \n",
       "S.No                                                     \n",
       "1                       25 July, 2012 to 25 July, 2017   \n",
       "2                       25 July, 2007 to 25 July, 2012   \n",
       "3                       25 July, 2002 to 25 July, 2007   \n",
       "4                       25 July, 1997 to 25 July, 2002   \n",
       "5                       25 July, 1992 to 25 July, 1997   \n",
       "6                       25 July, 1987 to 25 July, 1992   \n",
       "7                       25 July, 1982 to 25 July, 1987   \n",
       "8                       25 July, 1977 to 25 July, 1982   \n",
       "9                  24 August, 1974 to 11 February, 1977  \n",
       "10     3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                          13 May, 1967 to 3 May, 1969  \n",
       "12                         13 May, 1962 to 13 May, 1967  \n",
       "13                     26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url: https://presidentofindia.nic.in/former-presidents.htm\n",
    "President(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479e902",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dfbd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_team(x):\n",
    "    \n",
    "#     requesting the url\n",
    "    Crick= requests.get(x)\n",
    "#     scraping the content\n",
    "    Cricket=BeautifulSoup(Crick.content)\n",
    "\n",
    "#     empty list to store data\n",
    "    team=[]\n",
    "    rating=[]\n",
    "    match=[]\n",
    "    points=[]\n",
    "    ranking=[]\n",
    "    container=[]\n",
    "    \n",
    "#     fetch the required data\n",
    "    for i in Cricket.find_all('span',class_=\"u-hide-phablet\"):\n",
    "        team.append(i.text)\n",
    "\n",
    "    for i in Cricket.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        rating.append(i.text.split(\"\\n\"))\n",
    "\n",
    "    for i in Cricket.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "        rating.append(i.text)\n",
    "\n",
    "#         trim the white spaces \n",
    "    rating[0]=rating[0][1].strip()\n",
    "    \n",
    "    \n",
    "    for i in Cricket.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "        match.append(i.text)\n",
    "        \n",
    "    for i in Cricket.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "        points.append(i.text)\n",
    "    \n",
    "    \n",
    "    for i in Cricket.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "        container.append(i.text)\n",
    "    \n",
    "    for j in range(0,len(container)):\n",
    "        l=list(range(1,30,2))\n",
    "        if j in l:\n",
    "            points.append(container[j])\n",
    "        elif j not in l:\n",
    "            match.append(container[j])\n",
    "\n",
    "        \n",
    "    for i in range(1,len(points)):\n",
    "        ranking.append(i)\n",
    "\n",
    "#   limiting the lists to 10 elements only\n",
    "    ranking=ranking[0:10]\n",
    "    team=team[0:10]\n",
    "    match=match[0:10]\n",
    "    points=points[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "#     create a dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Team\":team,\"Matches\":match,\"Points\": points,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     store the data\n",
    "    DATA.to_csv('odi_team.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "791dc5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>12</td>\n",
       "      <td>1,505</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>19</td>\n",
       "      <td>2,353</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>1,929</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>22</td>\n",
       "      <td>2,304</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>16</td>\n",
       "      <td>1,635</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,872</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,275</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>2,086</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>26</td>\n",
       "      <td>1,885</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>15</td>\n",
       "      <td>986</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team Matches Points Rating\n",
       "S.No                                    \n",
       "1      New Zealand      12  1,505    125\n",
       "2          England      19  2,353    124\n",
       "3        Australia      18  1,929    107\n",
       "4            India      22  2,304    105\n",
       "5         Pakistan      16  1,635    102\n",
       "6     South Africa      19  1,872     99\n",
       "7       Bangladesh      24  2,275     95\n",
       "8        Sri Lanka      24  2,086     87\n",
       "9      West Indies      26  1,885     73\n",
       "10     Afghanistan      15    986     66"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url: https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "odi_team(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a0834",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c0570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batsmen(x):\n",
    "\n",
    "#     requesting the url\n",
    "    Cricket= requests.get(x)\n",
    "#     scraping the content\n",
    "    batsmen=BeautifulSoup(Cricket.content)\n",
    "\n",
    "#     empty list for the data storing\n",
    "    team=[]\n",
    "    rating=[]\n",
    "    player=[]\n",
    "    ranking=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "    for i in batsmen.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "        player.append(i.text)\n",
    "        \n",
    "    for i in batsmen.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        player.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in range(1,len(player)):\n",
    "        player[i]=player[i][1]\n",
    "        \n",
    "    for i in batsmen.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "        team.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in batsmen.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        team.append(i.text)\n",
    "        \n",
    "#      trimming white spaces\n",
    "    team[0]=team[0][2].strip()\n",
    "    \n",
    "    for i in batsmen.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    for i in batsmen.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "        \n",
    "    for i in range(1,11,1):\n",
    "        ranking.append(i)\n",
    "#   limiting the lists to 10 elements only\n",
    "    team=team[0:10]\n",
    "    player=player[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating a dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Batsman\":player,\"Team\":team,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     storing data\n",
    "    DATA.to_csv('Batsmen.csv')\n",
    "\n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a42b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Batsman Team Rating\n",
       "S.No                                   \n",
       "1                Babar Azam  PAK    891\n",
       "2               Virat Kohli  IND    811\n",
       "3               Imam-ul-Haq  PAK    795\n",
       "4              Rohit Sharma  IND    791\n",
       "5           Quinton de Kock   SA    789\n",
       "6            Jonny Bairstow  ENG    775\n",
       "7               Ross Taylor   NZ    775\n",
       "8     Rassie van der Dussen   SA    769\n",
       "9              David Warner  AUS    750\n",
       "10              Aaron Finch  AUS    745"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  url : https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\n",
    "Batsmen(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054133d6",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3413b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bowler(x):\n",
    "\n",
    "#   requesting the url\n",
    "    Cricket= requests.get(x)\n",
    "#     page content scraped\n",
    "    Bowler=BeautifulSoup(Cricket.content)\n",
    "\n",
    "# empty list to store data\n",
    "    team=[]\n",
    "    rating=[]\n",
    "    player=[]\n",
    "    ranking=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "    for i in Bowler.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "        player.append(i.text)\n",
    "        \n",
    "    for i in Bowler.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        player.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in range(1,len(player)):\n",
    "        player[i]=player[i][1]\n",
    "        \n",
    "    for i in Bowler.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "        team.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in Bowler.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        team.append(i.text)\n",
    "#     trimming white spaces and taking only required element   \n",
    "    team[0]=team[0][2].strip()\n",
    "    \n",
    "    for i in Bowler.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    for i in Bowler.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "        \n",
    "    for i in range(1,11,1):\n",
    "        ranking.append(i)\n",
    "    \n",
    "#   limiting the lists to 10 elements only\n",
    "    team=team[0:10]\n",
    "    player=player[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating the datframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Bowler\":player,\"Team\":team,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     string the data\n",
    "    DATA.to_csv('Bowler.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8242a217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Bowler Team Rating\n",
       "S.No                              \n",
       "1          Trent Boult   NZ    726\n",
       "2         Chris Woakes  ENG    700\n",
       "3       Josh Hazlewood  AUS    698\n",
       "4           Matt Henry   NZ    683\n",
       "5     Mujeeb Ur Rahman  AFG    681\n",
       "6       Jasprit Bumrah  IND    679\n",
       "7       Shaheen Afridi  PAK    671\n",
       "8         Mehedi Hasan  BAN    661\n",
       "9      Shakib Al Hasan  BAN    657\n",
       "10         Rashid Khan  AFG    650"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url: https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\n",
    "Bowler(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794af9d9",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbbbd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Women_crick(x):\n",
    "    \n",
    "#   requesting the url\n",
    "    Cricket= requests.get(x)\n",
    "#     page content scraped\n",
    "    women=BeautifulSoup(Cricket.content)\n",
    "\n",
    "# empty list to store data\n",
    "    team=[]\n",
    "    point=[]\n",
    "    matches=[]\n",
    "    rating=[]\n",
    "    ranking=[]\n",
    "    container=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "    for i in women.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "        point.append(i.text)\n",
    "    \n",
    "    for i in women.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "        matches.append(i.text)\n",
    "        \n",
    "\n",
    "    for i in women.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "        container.append(i.text)\n",
    "        \n",
    "    for k in container:\n",
    "        m=container.index(k)\n",
    "        l=[0,2,4,6,8,10,12,14,16,18,20]\n",
    "        if(m in l):\n",
    "            matches.append(k)\n",
    "        else:\n",
    "            point.append(k)\n",
    "        \n",
    "        \n",
    "    for i in women.find_all('span',class_=\"u-hide-phablet\"):\n",
    "        team.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in women.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        rating.append(i.text.split('\\n'))\n",
    "    \n",
    "#     trimming the white spaces\n",
    "    rating[0]=rating[0][1].strip()\n",
    "        \n",
    "    for i in women.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "        \n",
    "    for i in range(1,11,1):\n",
    "        ranking.append(i)\n",
    "    \n",
    "#   limiting the lists to 10 elements only\n",
    "    team=team[0:10]\n",
    "    matches=matches[0:10]\n",
    "    point=point[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating the datframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Team\":team,\"Matches\":matches,\"Points\":point,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     storing the data\n",
    "    DATA.to_csv('ODI_WOMEN_TEAM.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e38ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.icc-cricket.com/rankings/womens/team-rankings/odi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,840</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>28</td>\n",
       "      <td>3,504</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,533</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>2,878</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,030</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>28</td>\n",
       "      <td>2,481</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>936</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>26</td>\n",
       "      <td>1,752</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team Matches Points Rating\n",
       "S.No                                    \n",
       "1        Australia      29  4,840    167\n",
       "2     South Africa      28  3,504    125\n",
       "3          England      30  3,533    118\n",
       "4            India      29  2,878     99\n",
       "5      New Zealand      31  3,030     98\n",
       "6      West Indies      28  2,481     89\n",
       "7       Bangladesh      12    936     78\n",
       "8         Pakistan      26  1,752     67\n",
       "9          Ireland       5    240     48\n",
       "10       Sri Lanka       5    233     47"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url : https://www.icc-cricket.com/rankings/womens/team-rankings/odi\n",
    "Women_crick(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42c3e37f",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "646e3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batswomen(x):\n",
    "    \n",
    "#   requesting the url\n",
    "    Cricket= requests.get(x)\n",
    "#     page content scraped\n",
    "    batswomen=BeautifulSoup(Cricket.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    team=[]\n",
    "    player=[]\n",
    "    rating=[]\n",
    "    ranking=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "\n",
    "    for i in batswomen.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "        player.append(i.text)\n",
    "    for i in batswomen.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        player.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in range(1,len(player)):\n",
    "        player[i]=player[i][1]\n",
    "        \n",
    "    for i in batswomen.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "        team.append(i.text.split('\\n'))\n",
    "#     indexing the required element    \n",
    "    team[0]=team[0][2]\n",
    "    \n",
    "    for i in batswomen.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        team.append(i.text)\n",
    "\n",
    "    for i in batswomen.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "        rating.append(i.text)\n",
    "    for i in batswomen.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "        \n",
    "    for i in range(1,11,1):\n",
    "        ranking.append(i)\n",
    "\n",
    "#   limiting the lists to 10 elements only\n",
    "    team=team[0:10]\n",
    "    player=player[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creatting the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Team\":team,\"Player\":player,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     storing the data\n",
    "    DATA.to_csv('Bats_Women.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f3d2936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL\n",
      "https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SA</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IND</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IND</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team             Player Rating\n",
       "S.No                               \n",
       "1     AUS       Alyssa Healy    785\n",
       "2     ENG     Natalie Sciver    750\n",
       "3     AUS        Beth Mooney    748\n",
       "4      SA    Laura Wolvaardt    722\n",
       "5     AUS        Meg Lanning    710\n",
       "6     AUS     Rachael Haynes    701\n",
       "7     IND        Mithali Raj    686\n",
       "8      NZ  Amy Satterthwaite    681\n",
       "9     IND    Smriti Mandhana    669\n",
       "10    ENG     Tammy Beaumont    659"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url: https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\n",
    "Batswomen(input(\"Enter the URL\\n\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d313570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de14b9f2",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd9ff0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Women_allrounder(x):\n",
    "\n",
    "#   requesting the url\n",
    "    Cricket= requests.get(x)\n",
    "#     page content scraped\n",
    "    allrounder=BeautifulSoup(Cricket.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    team=[]\n",
    "    player=[]\n",
    "    rating=[]\n",
    "    ranking=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "\n",
    "    for i in allrounder.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "        player.append(i.text)\n",
    "    for i in allrounder.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        player.append(i.text.split('\\n'))\n",
    "\n",
    "    for i in range(1,len(player)):\n",
    "        player[i]=player[i][1]\n",
    "        \n",
    "    for i in allrounder.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "        team.append(i.text.split('\\n'))\n",
    "#     index the required element    \n",
    "    team[0]=team[0][2]\n",
    "    \n",
    "    for i in allrounder.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        team.append(i.text)\n",
    "\n",
    "    for i in allrounder.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "        rating.append(i.text)\n",
    "    for i in allrounder.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        rating.append(i.text)\n",
    "    \n",
    "        \n",
    "    for i in range(1,11,1):\n",
    "        ranking.append(i)\n",
    "    \n",
    "#   limiting the lists to 10 elements only\n",
    "    team=team[0:10]\n",
    "    player=player[0:10]\n",
    "    rating=rating[0:10]\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":ranking,\"Team\":team,\"Player\":player,\"Rating\":rating})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "#     storing the data\n",
    "    DATA.to_csv('All rounder Women.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d02bb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the url\n",
      "https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IND</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IND</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team            Player Rating\n",
       "S.No                              \n",
       "1     ENG    Natalie Sciver    393\n",
       "2     AUS      Ellyse Perry    374\n",
       "3      SA    Marizanne Kapp    359\n",
       "4      WI   Hayley Matthews    338\n",
       "5      NZ       Amelia Kerr    335\n",
       "6     AUS  Ashleigh Gardner    269\n",
       "7     IND     Deepti Sharma    249\n",
       "8     AUS     Jess Jonassen    245\n",
       "9     ENG   Katherine Brunt    221\n",
       "10    IND    Jhulan Goswami    217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url: https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\n",
    "Women_allrounder(input(\"Enter the url\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb26a08",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb0fb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cnbc(x):\n",
    "\n",
    "#   requesting the url\n",
    "    news= requests.get(x)\n",
    "#     page content scraped\n",
    "    cnbc=BeautifulSoup(news.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    rank=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "\n",
    "    for i in cnbc.find_all('a',class_=\"LatestNews-headline\"):\n",
    "        x.append(i.text)\n",
    "        \n",
    "    for i in cnbc.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "        y.append(i.text)\n",
    "        \n",
    "    for link in cnbc.find_all('a',class_=\"LatestNews-headline\"):\n",
    "        if link.has_attr('href'):\n",
    "            z.append(link.attrs['href'])\n",
    "    for i in range(1,len(y)+1):\n",
    "        rank.append(i)\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":rank,\"new\":x,\"time\":y,\"link\":z})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "#     storing the data\n",
    "    DATA.to_csv('CNBC.csv')\n",
    "\n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af260cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE URL\n",
      "https://www.cnbc.com/world/?region=world\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European stocks set to nudge higher, tracking ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/europe-markets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top recruitment and tech execs give their tips...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/top-execs-give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global recession? Not yet, economists say — bu...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/no-global-rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PropertyGuru CEO sees 'massive gap' between de...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/propertyguru-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beijing, Shanghai start to reopen as Covid cas...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/beijing-shangh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wall Street banks name global stocks and secto...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/buy-this-dip-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'We see a clear role for alternatives': Pros o...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/stocks-top-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japan's Nikkei jumps 2% as Asia-Pacific stocks...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/30/asia-markets-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Republicans, Democrats spar over gun regulatio...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/republicans-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'Top Gun: Maverick' grosses $124 million – Tom...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/top-gun-maveri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Flight cancellations ease after rocky start to...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/flight-cancell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'Secret’ to getting better at small talk, from...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/secret-to-gett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Former Disney CEO Bob Iger takes stake in Aust...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/former-disney-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sean Connery's 'James Bond' Aston Martin could...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/sean-connerys-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Netflix's fall has media investors questioning...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/netflix-and-ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Recession-fearing investors keep slashing the ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/recession-fear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Some investors got rich before a popular stabl...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/who-got-rich-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Your Social Security check might be taxed. Ho...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/-your-social-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Here are the top stock picks from UBS for the ...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/here-are-the-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Buy this ETF for exposure to the booming EV ma...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/buy-this-etf-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U.S. job market boosts some workers' prospects...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/us-job-market-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zelenskyy visits frontlines; Lithuania raises ...</td>\n",
       "      <td>24 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/29/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Successful parents do these 3 things with thei...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/successful-par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Now is the best time to book your summer vacat...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/now-is-the-bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>President Joe Biden says young people need the...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/president-joe-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>These 'safe' stocks are analysts' favorites to...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/stocks-like-t-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Government lab in Idaho is researching fusion,...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/idaho-national...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Choice between pre-tax and Roth 401(k) plans t...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/choice-between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Start-up investors warn of dark days as boom t...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/start-up-inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>This couple bought and renovated a mansion for...</td>\n",
       "      <td>May 28, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/05/28/unlocked-look-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    new          time  \\\n",
       "S.No                                                                    \n",
       "1     European stocks set to nudge higher, tracking ...    1 Hour Ago   \n",
       "2     Top recruitment and tech execs give their tips...   2 Hours Ago   \n",
       "3     Global recession? Not yet, economists say — bu...   2 Hours Ago   \n",
       "4     PropertyGuru CEO sees 'massive gap' between de...   2 Hours Ago   \n",
       "5     Beijing, Shanghai start to reopen as Covid cas...   3 Hours Ago   \n",
       "6     Wall Street banks name global stocks and secto...   5 Hours Ago   \n",
       "7     'We see a clear role for alternatives': Pros o...   5 Hours Ago   \n",
       "8     Japan's Nikkei jumps 2% as Asia-Pacific stocks...   7 Hours Ago   \n",
       "9     Republicans, Democrats spar over gun regulatio...  15 Hours Ago   \n",
       "10    'Top Gun: Maverick' grosses $124 million – Tom...  16 Hours Ago   \n",
       "11    Flight cancellations ease after rocky start to...  16 Hours Ago   \n",
       "12    'Secret’ to getting better at small talk, from...  17 Hours Ago   \n",
       "13    Former Disney CEO Bob Iger takes stake in Aust...  18 Hours Ago   \n",
       "14    Sean Connery's 'James Bond' Aston Martin could...  18 Hours Ago   \n",
       "15    Netflix's fall has media investors questioning...  18 Hours Ago   \n",
       "16    Recession-fearing investors keep slashing the ...  18 Hours Ago   \n",
       "17    Some investors got rich before a popular stabl...  18 Hours Ago   \n",
       "18     Your Social Security check might be taxed. Ho...  18 Hours Ago   \n",
       "19    Here are the top stock picks from UBS for the ...  20 Hours Ago   \n",
       "20    Buy this ETF for exposure to the booming EV ma...  20 Hours Ago   \n",
       "21    U.S. job market boosts some workers' prospects...  20 Hours Ago   \n",
       "22    Zelenskyy visits frontlines; Lithuania raises ...  24 Hours Ago   \n",
       "23    Successful parents do these 3 things with thei...  May 28, 2022   \n",
       "24    Now is the best time to book your summer vacat...  May 28, 2022   \n",
       "25    President Joe Biden says young people need the...  May 28, 2022   \n",
       "26    These 'safe' stocks are analysts' favorites to...  May 28, 2022   \n",
       "27    Government lab in Idaho is researching fusion,...  May 28, 2022   \n",
       "28    Choice between pre-tax and Roth 401(k) plans t...  May 28, 2022   \n",
       "29    Start-up investors warn of dark days as boom t...  May 28, 2022   \n",
       "30    This couple bought and renovated a mansion for...  May 28, 2022   \n",
       "\n",
       "                                                   link  \n",
       "S.No                                                     \n",
       "1     https://www.cnbc.com/2022/05/30/europe-markets...  \n",
       "2     https://www.cnbc.com/2022/05/30/top-execs-give...  \n",
       "3     https://www.cnbc.com/2022/05/30/no-global-rece...  \n",
       "4     https://www.cnbc.com/2022/05/30/propertyguru-c...  \n",
       "5     https://www.cnbc.com/2022/05/30/beijing-shangh...  \n",
       "6     https://www.cnbc.com/2022/05/30/buy-this-dip-w...  \n",
       "7     https://www.cnbc.com/2022/05/30/stocks-top-pro...  \n",
       "8     https://www.cnbc.com/2022/05/30/asia-markets-c...  \n",
       "9     https://www.cnbc.com/2022/05/29/republicans-de...  \n",
       "10    https://www.cnbc.com/2022/05/29/top-gun-maveri...  \n",
       "11    https://www.cnbc.com/2022/05/29/flight-cancell...  \n",
       "12    https://www.cnbc.com/2022/05/29/secret-to-gett...  \n",
       "13    https://www.cnbc.com/2022/05/29/former-disney-...  \n",
       "14    https://www.cnbc.com/2022/05/29/sean-connerys-...  \n",
       "15    https://www.cnbc.com/2022/05/29/netflix-and-ri...  \n",
       "16    https://www.cnbc.com/2022/05/29/recession-fear...  \n",
       "17    https://www.cnbc.com/2022/05/29/who-got-rich-b...  \n",
       "18    https://www.cnbc.com/2022/05/29/-your-social-s...  \n",
       "19    https://www.cnbc.com/2022/05/29/here-are-the-t...  \n",
       "20    https://www.cnbc.com/2022/05/29/buy-this-etf-f...  \n",
       "21    https://www.cnbc.com/2022/05/29/us-job-market-...  \n",
       "22    https://www.cnbc.com/2022/05/29/russia-ukraine...  \n",
       "23    https://www.cnbc.com/2022/05/28/successful-par...  \n",
       "24    https://www.cnbc.com/2022/05/28/now-is-the-bes...  \n",
       "25    https://www.cnbc.com/2022/05/28/president-joe-...  \n",
       "26    https://www.cnbc.com/2022/05/28/stocks-like-t-...  \n",
       "27    https://www.cnbc.com/2022/05/28/idaho-national...  \n",
       "28    https://www.cnbc.com/2022/05/28/choice-between...  \n",
       "29    https://www.cnbc.com/2022/05/28/start-up-inves...  \n",
       "30    https://www.cnbc.com/2022/05/28/unlocked-look-...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url: https://www.cnbc.com/world/?region=world\n",
    "Cnbc(input(\"ENTER THE URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf944c",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details :\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdd65c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI(x):\n",
    "\n",
    "#   requesting the url\n",
    "    article= requests.get(x)\n",
    "#     page content scraped\n",
    "    ai=BeautifulSoup(article.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    Date=[]\n",
    "    author=[]\n",
    "    name=[]\n",
    "    z=[]\n",
    "    rank=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "\n",
    "    for i in ai.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "        Date.append(i.text)\n",
    "        \n",
    "    for i in ai.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "        author.append(i.text)\n",
    "        \n",
    "    for i in ai.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "        name.append(i.text) \n",
    "    \n",
    "    for link in ai.find_all('a',class_=\"sc-5smygv-0 nrDZj\"):\n",
    "        if link.has_attr('href'):\n",
    "            z.append(link.attrs['href'])\n",
    "    \n",
    "    for k in range(1,len(name)+1):\n",
    "        rank.append(k)\n",
    "            \n",
    "    import pandas as pd\n",
    "#     creating the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":rank,\"Published On\":Date,\"Title\":name,\"Authors\":author,\"link\":z})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "#     storing the data\n",
    "    DATA.to_csv('AI_article.csv')\n",
    "\n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c2bfc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE URL\n",
      "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published On</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 2021</td>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 2021</td>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>October 2015</td>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August 1998</td>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>June 2017</td>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>February 2019</td>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>April 2021</td>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>February 2015</td>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>August 1999</td>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>March 2020</td>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>February 2021</td>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>October 2007</td>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>August 2016</td>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>April 2021</td>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>December 1997</td>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>August 2021</td>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>September 2021</td>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>June 2021</td>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>December 2016</td>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>September 2021</td>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>May 2021</td>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>January 2014</td>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>December 1997</td>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>October 2021</td>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>February 2010</td>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Published On                                              Title  \\\n",
       "S.No                                                                      \n",
       "1       October 2021                                   Reward is enough   \n",
       "2       October 2021                          Making sense of raw input   \n",
       "3       October 2015  Law and logic: A review from an argumentation ...   \n",
       "4        August 1998             Creativity and artificial intelligence   \n",
       "5          June 2017  Artificial cognition for social human–robot in...   \n",
       "6      February 2019  Explanation in artificial intelligence: Insigh...   \n",
       "7         April 2021                      Making sense of sensory input   \n",
       "8      February 2015  Conflict-based search for optimal multi-agent ...   \n",
       "9        August 1999  Between MDPs and semi-MDPs: A framework for te...   \n",
       "10        March 2020  The Hanabi challenge: A new frontier for AI re...   \n",
       "11     February 2021  Evaluating XAI: A comparison of rule-based and...   \n",
       "12      October 2007           Argumentation in artificial intelligence   \n",
       "13       August 2016  Algorithms for computing strategies in two-pla...   \n",
       "14        April 2021      Multiple object tracking: A literature review   \n",
       "15     December 1997  Selection of relevant features and examples in...   \n",
       "16       August 2021  A survey of inverse reinforcement learning: Ch...   \n",
       "17    September 2021  Explaining individual predictions when feature...   \n",
       "18         June 2021  A review of possible effects of cognitive bias...   \n",
       "19     December 2016  Integrating social power into the decision-mak...   \n",
       "20    September 2021  “That's (not) the output I expected!” On the r...   \n",
       "21          May 2021  Explaining black-box classifiers using post-ho...   \n",
       "22      January 2014  Algorithm runtime prediction: Methods & evalua...   \n",
       "23     December 1997              Wrappers for feature subset selection   \n",
       "24      October 2021  Commonsense visual sensemaking for autonomous ...   \n",
       "25     February 2010         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                                Authors  \\\n",
       "S.No                                                      \n",
       "1     Silver, David, Singh, Satinder, Precup, Doina,...   \n",
       "2             Evans, Richard, Bošnjak, Matko and 5 more   \n",
       "3                     Prakken, Henry, Sartor, Giovanni    \n",
       "4                                   Boden, Margaret A.    \n",
       "5       Lemaignan, Séverin, Warnier, Mathieu and 3 more   \n",
       "6                                          Miller, Tim    \n",
       "7     Evans, Richard, Hernández-Orallo, José and 3 more   \n",
       "8     Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   \n",
       "9     Sutton, Richard S., Precup, Doina, Singh, Sati...   \n",
       "10          Bard, Nolan, Foerster, Jakob N. and 13 more   \n",
       "11    van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   \n",
       "12                 Bench-Capon, T.J.M., Dunne, Paul E.    \n",
       "13         Bošanský, Branislav, Lisý, Viliam and 3 more   \n",
       "14               Luo, Wenhan, Xing, Junliang and 4 more   \n",
       "15                        Blum, Avrim L., Langley, Pat    \n",
       "16                     Arora, Saurabh, Doshi, Prashant    \n",
       "17        Aas, Kjersti, Jullum, Martin, Løland, Anders    \n",
       "18    Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...   \n",
       "19      Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    \n",
       "20                        Riveiro, Maria, Thill, Serge    \n",
       "21    Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...   \n",
       "22    Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...   \n",
       "23                        Kohavi, Ron, John, George H.    \n",
       "24    Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...   \n",
       "25                                     Ying, Mingsheng    \n",
       "\n",
       "                                                   link  \n",
       "S.No                                                     \n",
       "1     https://www.sciencedirect.com/science/article/...  \n",
       "2     https://www.sciencedirect.com/science/article/...  \n",
       "3     https://www.sciencedirect.com/science/article/...  \n",
       "4     https://www.sciencedirect.com/science/article/...  \n",
       "5     https://www.sciencedirect.com/science/article/...  \n",
       "6     https://www.sciencedirect.com/science/article/...  \n",
       "7     https://www.sciencedirect.com/science/article/...  \n",
       "8     https://www.sciencedirect.com/science/article/...  \n",
       "9     https://www.sciencedirect.com/science/article/...  \n",
       "10    https://www.sciencedirect.com/science/article/...  \n",
       "11    https://www.sciencedirect.com/science/article/...  \n",
       "12    https://www.sciencedirect.com/science/article/...  \n",
       "13    https://www.sciencedirect.com/science/article/...  \n",
       "14    https://www.sciencedirect.com/science/article/...  \n",
       "15    https://www.sciencedirect.com/science/article/...  \n",
       "16    https://www.sciencedirect.com/science/article/...  \n",
       "17    https://www.sciencedirect.com/science/article/...  \n",
       "18    https://www.sciencedirect.com/science/article/...  \n",
       "19    https://www.sciencedirect.com/science/article/...  \n",
       "20    https://www.sciencedirect.com/science/article/...  \n",
       "21    https://www.sciencedirect.com/science/article/...  \n",
       "22    https://www.sciencedirect.com/science/article/...  \n",
       "23    https://www.sciencedirect.com/science/article/...  \n",
       "24    https://www.sciencedirect.com/science/article/...  \n",
       "25    https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url: https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "AI(input(\"ENTER THE URL\\n\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971c0d5",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from https://www.dineout.co.in/delhi-restaurants/buffet-special :\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05bc02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dine_Out(x):\n",
    "\n",
    "#   requesting the url\n",
    "    Dine= requests.get(x)\n",
    "#     page content scraped\n",
    "    food=BeautifulSoup(Dine.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    cusine=[]\n",
    "    name=[]\n",
    "    location=[]\n",
    "    rating=[]\n",
    "    cost=[]\n",
    "    z=[]\n",
    "    rank=[]\n",
    "    \n",
    "#     fetching the required data\n",
    "\n",
    "    for i in food.find_all('img',class_=\"no-img\"):\n",
    "        z.append(i['data-src'])\n",
    "        \n",
    "    for i in food.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "        location.append(i.text)\n",
    "        \n",
    "    for i in food.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "        name.append(i.text) \n",
    "    \n",
    "    for l in food.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "        cusine.append(l.text.split(\"|\"))\n",
    "    \n",
    "    for i in range(len(cusine)):\n",
    "        cost.append(cusine[i][0])\n",
    "        cusine[i]=cusine[i][1]\n",
    "          \n",
    "    for l in food.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "        rating.append(l.text)\n",
    "            \n",
    "  \n",
    "    for k in range(1,len(name)+1):\n",
    "        rank.append(k)\n",
    "            \n",
    "    import pandas as pd\n",
    "#     creating the dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":rank,\"Retaurant\":name,\"Cusine\":cusine,\"Location\":location,\"Rating\":rating,\"Cost\":cost,\"image\":z})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "#     storing the data\n",
    "    DATA.to_csv('Dine_Out.csv')\n",
    "\n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62521c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE URL\n",
      "https://www.dineout.co.in/delhi-restaurants/buffet-special\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retaurant</th>\n",
       "      <th>Cusine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cost</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹ 1,400 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>₹ 1,700 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian, Mughlai, Desserts, Beverages</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>₹ 1,500 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>European, Italian, Asian, Continental</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "      <td>₹ 3,400 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Retaurant  \\\n",
       "S.No                                     \n",
       "1                      Castle Barbeque   \n",
       "2                      Jungle Jamboree   \n",
       "3                      Castle Barbeque   \n",
       "4                           Cafe Knosh   \n",
       "5                 The Barbeque Company   \n",
       "6                          India Grill   \n",
       "7                       Delhi Barbeque   \n",
       "8     The Monarch - Bar Be Que Village   \n",
       "9                           World Cafe   \n",
       "10                   Indian Grill Room   \n",
       "11                     Mad 4 Bar B Que   \n",
       "12                         Barbeque 29   \n",
       "13                          Glasshouse   \n",
       "\n",
       "                                           Cusine  \\\n",
       "S.No                                                \n",
       "1                           North Indian, Chinese   \n",
       "2                    North Indian, Asian, Italian   \n",
       "3                           Chinese, North Indian   \n",
       "4                            Italian, Continental   \n",
       "5                           North Indian, Chinese   \n",
       "6                           North Indian, Italian   \n",
       "7                                    North Indian   \n",
       "8                                    North Indian   \n",
       "9                           North Indian, Italian   \n",
       "10                          North Indian, Mughlai   \n",
       "11                                   North Indian   \n",
       "12     North Indian, Mughlai, Desserts, Beverages   \n",
       "13          European, Italian, Asian, Continental   \n",
       "\n",
       "                                               Location Rating  \\\n",
       "S.No                                                             \n",
       "1                        Connaught Place, Central Delhi    3.5   \n",
       "2                3CS Mall,Lajpat Nagar - 3, South Delhi    3.9   \n",
       "3                Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "4     The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "5                    Gardens Galleria,Sector 38A, Noida      4   \n",
       "6                  Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "7        Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "8     Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "9      Vibe by The Lalit Traveller,Sector 35, Faridabad    4.2   \n",
       "10     Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "11                                 Sector 29, Faridabad    3.6   \n",
       "12                                       NIT, Faridabad    4.2   \n",
       "13    DoubleTree By Hilton Gurugram Baani Square,Sec...      4   \n",
       "\n",
       "                         Cost  \\\n",
       "S.No                            \n",
       "1     ₹ 2,000 for 2 (approx)    \n",
       "2     ₹ 1,400 for 2 (approx)    \n",
       "3     ₹ 2,000 for 2 (approx)    \n",
       "4     ₹ 3,000 for 2 (approx)    \n",
       "5     ₹ 1,700 for 2 (approx)    \n",
       "6     ₹ 2,400 for 2 (approx)    \n",
       "7     ₹ 1,800 for 2 (approx)    \n",
       "8     ₹ 1,900 for 2 (approx)    \n",
       "9     ₹ 2,400 for 2 (approx)    \n",
       "10    ₹ 2,200 for 2 (approx)    \n",
       "11      ₹ 800 for 2 (approx)    \n",
       "12    ₹ 1,500 for 2 (approx)    \n",
       "13    ₹ 3,400 for 2 (approx)    \n",
       "\n",
       "                                                  image  \n",
       "S.No                                                     \n",
       "1     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10    https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11    https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12    https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13    https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url : https://www.dineout.co.in/delhi-restaurants/buffet-special\n",
    "Dine_Out(input(\"ENTER THE URL\\n\",) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040764c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e286996",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "# https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "# i) Rank\n",
    "# ii) Publication\n",
    "# iii) h5-index\n",
    "# iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687d635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publication(x):\n",
    "\n",
    "#   requesting the url\n",
    "    english= requests.get(x)\n",
    "#     page content scraped\n",
    "    scholar=BeautifulSoup(english.content)\n",
    "    \n",
    "# empty list to store data\n",
    "    rank=[]\n",
    "    publication=[]\n",
    "    h5_index=[]\n",
    "    h5_median=[]\n",
    "    obj=[]\n",
    "\n",
    "#     fetching the required data\n",
    "\n",
    "    for i in scholar.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "        publication.append(i.text)\n",
    "        \n",
    "    for i in scholar.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "        rank.append(i.text)\n",
    "        \n",
    "    for i in scholar.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "        h5_index.append(i.text)\n",
    "    \n",
    "    for i in scholar.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "        h5_median.append(i.text)\n",
    "    \n",
    "    import pandas as pd\n",
    "#     creating a dataframe\n",
    "    DATA=pd.DataFrame({\"S.No\":rank,\"Publication\":publication,\"H5-Index\":h5_index,\"H5-Median\":h5_median})\n",
    "    \n",
    "    DATA.set_index('S.No',inplace =True)\n",
    "    \n",
    "#     storing the data\n",
    "    DATA.to_csv('scholar.csv')\n",
    "    \n",
    "#     display the data\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99876088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE URL\n",
      "https://scholar.google.com/citations?view_op=top_venues&hl=en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>H5-Index</th>\n",
       "      <th>H5-Median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>Nature</td>\n",
       "      <td>414</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>410</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>Science</td>\n",
       "      <td>391</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>356</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>The Lancet</td>\n",
       "      <td>345</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.</th>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.</th>\n",
       "      <td>Small</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.</th>\n",
       "      <td>Nature Immunology</td>\n",
       "      <td>133</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.</th>\n",
       "      <td>JAMA Oncology</td>\n",
       "      <td>133</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.</th>\n",
       "      <td>The Lancet Neurology</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Publication H5-Index H5-Median\n",
       "S.No                                                                      \n",
       "1.                                               Nature      414       607\n",
       "2.                  The New England Journal of Medicine      410       704\n",
       "3.                                              Science      391       564\n",
       "4.    IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
       "5.                                           The Lancet      345       600\n",
       "...                                                 ...      ...       ...\n",
       "96.                             Frontiers in Immunology      134       177\n",
       "97.                                               Small      134       173\n",
       "98.                                   Nature Immunology      133       210\n",
       "99.                                       JAMA Oncology      133       202\n",
       "100.                               The Lancet Neurology      133       200\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url : https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "publication(input(\"ENTER THE URL\\n\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafd0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
